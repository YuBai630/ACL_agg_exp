import os
import sys
import time
import warnings
import argparse
import json

# å¿½ç•¥ä¸ np.bool ç›¸å…³çš„è­¦å‘Š
warnings.filterwarnings('ignore', category=FutureWarning)

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒï¼Œå¤„ç†åº“ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜"""
    try:
        # å…ˆå¯¼å…¥numpyå¹¶æ·»åŠ å‘åå…¼å®¹æ€§
        import numpy as np
        if not hasattr(np, 'bool'):
            np.bool = bool
        if not hasattr(np, 'object'):
            np.object = object
        if not hasattr(np, 'float'):
            np.float = float
        if not hasattr(np, 'int'):
            np.int = int
        
        # å†å¯¼å…¥pandas
        import pandas as pd
        print(f"âœ… æˆåŠŸå¯¼å…¥ç¯å¢ƒ: NumPy {np.__version__}, Pandas {pd.__version__}")
        return True
    except Exception as e:
        print(f"âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥: {str(e)}")
        print("è¯·å°è¯•æ›´æ–° Pandas æˆ–é™çº§ NumPy ç‰ˆæœ¬:")
        print("  pip install pandas --upgrade")
        print("  æˆ–")
        print("  pip install numpy==1.19.5")
        return False

def check_data_file():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè¿”å›æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„"""
    # è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # å°è¯•ä¸åŒçš„ç›¸å¯¹è·¯å¾„ç»„åˆ
    possible_paths = [
        os.path.join(current_dir, "../../data/W2.csv"),
        os.path.join(current_dir, "../../../data/W2.csv"),
        os.path.join(current_dir, "../../data/W2.csv"),
        os.path.normpath(os.path.join(current_dir, "../../data/W2.csv")),
        os.path.abspath(os.path.join(current_dir, "../../data/W2.csv")),
        "D:/afterWork/ACL_agg_exp/data/W2.csv"  # ç›´æ¥ä½¿ç”¨ç»å¯¹è·¯å¾„
    ]
    
    # æ£€æŸ¥æ¯ä¸ªå¯èƒ½çš„è·¯å¾„
    for path in possible_paths:
        if os.path.exists(path):
            print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {path}")
            return path
    
    print("âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ W2.csv")
    return None

def load_ac_configs():
    """åŠ è½½ç©ºè°ƒé…ç½®æ•°æ®"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        ac_data_path = os.path.join(current_dir, "ac_data.json")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(ac_data_path):
            print(f"âŒ æœªæ‰¾åˆ°ç©ºè°ƒé…ç½®æ–‡ä»¶: {ac_data_path}")
            return None
            
        with open(ac_data_path, 'r', encoding='utf-8') as f:
            ac_configs = json.load(f)
        
        print(f"âœ… æˆåŠŸåŠ è½½{len(ac_configs)}ä¸ªç©ºè°ƒé…ç½®")
        return ac_configs
    except Exception as e:
        print(f"âŒ åŠ è½½ç©ºè°ƒé…ç½®å¤±è´¥: {str(e)}")
        return None

def get_available_years(data_file_path):
    """è·å–æ•°æ®æ–‡ä»¶ä¸­å¯ç”¨çš„å¹´ä»½åˆ—è¡¨"""
    try:
        import pandas as pd
        import numpy as np
        
        # æ·»åŠ NumPyå…¼å®¹æ€§ä¿®å¤
        if not hasattr(np, 'bool'):
            np.bool = bool
        if not hasattr(np, 'object'):
            np.object = object
        
        # è¯»å–æ•°æ®æ–‡ä»¶
        print(f"æ­£åœ¨è¯»å–æ•°æ®æ–‡ä»¶ä»¥è·å–å¯ç”¨å¹´ä»½...")
        w2_data = pd.read_csv(data_file_path)
        
        # æå–å¹´ä»½
        years = set()
        for time_str in w2_data['Time']:
            try:
                year = time_str.split('/')[0]
                if len(year) == 4 and year.isdigit():
                    years.add(year)
            except Exception:
                continue
        
        years_list = sorted(list(years))
        print(f"æ‰¾åˆ°{len(years_list)}ä¸ªå¯ç”¨å¹´ä»½: {years_list}")
        return years_list
    except Exception as e:
        print(f"è·å–å¯ç”¨å¹´ä»½æ—¶å‡ºé”™: {str(e)}")
        return []

def generate_single_ac_multi_day_data(ac_config, target_year=None, start_day=0, batch_size=10, data_file_path=None):
    """
    ä¸ºå•ä¸ªç©ºè°ƒç”Ÿæˆå¤šå¹´å¤å­£æ•°æ®
    
    å‚æ•°:
    ac_config: ç©ºè°ƒé…ç½®å­—å…¸
    target_year: è¦å¤„ç†çš„ç›®æ ‡å¹´ä»½ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰å¹´ä»½
    start_day: å¼€å§‹å¤„ç†çš„å¤©æ•°ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€å¤©ï¼‰
    batch_size: æ¯æ‰¹å¤„ç†çš„å¤©æ•°
    data_file_path: æ•°æ®æ–‡ä»¶è·¯å¾„
    """
    from generate_data_V2 import ACOptimizerWithTempTarget
    import pandas as pd
    import numpy as np
    
    # æ·»åŠ NumPyå…¼å®¹æ€§ä¿®å¤
    if not hasattr(np, 'bool'):
        np.bool = bool
    if not hasattr(np, 'object'):
        np.object = object
    
    ac_id = ac_config['id']
    ac_type = ac_config['type']
    
    print(f"\nğŸ”§ å¼€å§‹å¤„ç†ç©ºè°ƒ: {ac_id} ({ac_type})")
    print(f"å‚æ•°: P_rated={ac_config['P_rated']}kW, T_range=[{ac_config['T_min']}, {ac_config['T_max']}]Â°C")
    
    try:
        # è¯»å–å¤å­£æ•°æ®
        w2_data = pd.read_csv(data_file_path)
        
        # ç­›é€‰å¤å­£æ•°æ®ï¼ˆ6-8æœˆï¼‰
        if target_year:
            summer_pattern = f"{target_year}/6|{target_year}/7|{target_year}/8"
            summer_indices = w2_data['Time'].str.contains(summer_pattern, na=False)
            print(f"  ç­›é€‰{target_year}å¹´çš„å¤å­£æ•°æ®")
        else:
            summer_indices = w2_data['Time'].str.contains('/6|/7|/8', na=False)
            print(f"  ç­›é€‰æ‰€æœ‰å¹´ä»½çš„å¤å­£æ•°æ®")
        
        if not summer_indices.any():
            print(f"  âŒ æœªæ‰¾åˆ°å¤å­£æ•°æ®")
            return
        
        summer_data = w2_data[summer_indices]
        print(f"  æ‰¾åˆ°å¤å­£æ•°æ®: {len(summer_data)}æ¡è®°å½•")
        
        # æå–æ—¥æœŸä¿¡æ¯
        dates = []
        for time_str in summer_data['Time']:
            date_part = time_str.split(' ')[0]
            dates.append(date_part)
        
        # è·å–å”¯ä¸€æ—¥æœŸå¹¶æ’åº
        unique_dates = list(set(dates))
        unique_dates.sort()
        
        total_days = len(unique_dates)
        print(f"  å¤å­£æ€»å¤©æ•°: {total_days}å¤©")
        
        # ç¡®å®šå®é™…å¤„ç†çš„å¤©æ•°
        remaining_days = total_days - start_day
        num_batches = (remaining_days + batch_size - 1) // batch_size
        
        # åˆ›å»ºå¸¦ç©ºè°ƒIDçš„è¾“å‡ºæ–‡ä»¶
        figures_dir = "../../figures"
        if not os.path.exists(figures_dir):
            os.makedirs(figures_dir)
        
        power_matrix_file = os.path.join(figures_dir, f"{ac_id}_multi_day_power_matrix.csv")
        stats_file = os.path.join(figures_dir, f"{ac_id}_multi_day_statistics.csv")
        timeseries_file = os.path.join(figures_dir, f"{ac_id}_multi_day_full_timeseries.csv")
        
        # åˆå§‹åŒ–ç»“æœæ–‡ä»¶
        all_results = []
        
        # é€æ‰¹å¤„ç†
        for batch in range(num_batches):
            batch_start = start_day + batch * batch_size
            batch_end = min(batch_start + batch_size, total_days)
            
            print(f"  æ‰¹æ¬¡{batch+1}/{num_batches}: ç¬¬{batch_start+1}-{batch_end}å¤©")
            
            process_dates = unique_dates[batch_start:batch_end]
            
            # é€å¤©å¤„ç†
            for day_idx, process_date in enumerate(process_dates):
                try:
                    # æå–å½“å¤©æ•°æ®
                    day_data = summer_data[[date.split(' ')[0] == process_date for date in summer_data['Time']]]
                    
                    if len(day_data) < 96:
                        print(f"    æ—¥æœŸ{process_date}: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                        continue
                    
                    # æå–æ¸©åº¦æ•°æ®ï¼ˆæ¯30åˆ†é’Ÿä¸€ä¸ªç‚¹ï¼‰
                    day_data_sorted = day_data.sort_values('Time')
                    fahrenheit_temps = day_data_sorted['Temperature(F)'].values[:96]
                    celsius_temps = (fahrenheit_temps - 32) * 5/9
                    
                    outdoor_temp_half_hour = []
                    for i in range(0, min(96, len(celsius_temps)), 2):
                        outdoor_temp_half_hour.append(celsius_temps[i])
                        if len(outdoor_temp_half_hour) >= 49:
                            break
                    
                    while len(outdoor_temp_half_hour) < 49:
                        outdoor_temp_half_hour.append(outdoor_temp_half_hour[-1])
                    
                    # åˆ›å»ºç©ºè°ƒä¼˜åŒ–å™¨
                    optimizer = ACOptimizerWithTempTarget(
                        T=48,
                        delta_t=0.5,
                        P_rated=ac_config['P_rated'],
                        T_min=ac_config['T_min'],
                        T_max=ac_config['T_max'],
                        eta=ac_config['eta'],
                        R=ac_config['R'],
                        C=ac_config['C'],
                        T_initial=23.5,
                        T_target=(ac_config['T_min'] + ac_config['T_max']) / 2.0,
                        target_type='custom'
                    )
                    
                    # è®¾ç½®å®¤å¤–æ¸©åº¦
                    optimizer.set_outdoor_temperature(outdoor_temp_half_hour)
                    
                    # æ±‚è§£ä¼˜åŒ–é—®é¢˜
                    success = optimizer.solve()
                    
                    if success:
                        # ä»ä¼˜åŒ–å™¨è·å–ç»“æœ
                        powers = optimizer.optimal_powers
                        temperatures = optimizer.optimal_temperatures
                        total_energy = optimizer.total_energy
                        
                        # ä¿å­˜ç»“æœ
                        day_result = {
                            'ac_id': ac_id,
                            'ac_type': ac_type,
                            'date': process_date,
                            'status': 'success',
                            'total_energy': total_energy,
                            'avg_power': sum(powers) / len(powers),
                            'max_power': max(powers),
                            'powers': powers,
                            'temperatures': temperatures
                        }
                        all_results.append(day_result)
                        print(f"    æ—¥æœŸ{process_date}: æˆåŠŸ (èƒ½è€—: {total_energy:.2f}kWh)")
                        
                    else:
                        print(f"    æ—¥æœŸ{process_date}: ä¼˜åŒ–å¤±è´¥")
                        
                except Exception as e:
                    print(f"    æ—¥æœŸ{process_date}: å¤„ç†å‡ºé”™ - {str(e)}")
                    continue
            
            # æ¯æ‰¹å¤„ç†åæš‚åœ
            time.sleep(2)
        
        # ä¿å­˜æ‰€æœ‰ç»“æœåˆ°CSVæ–‡ä»¶
        if all_results:
            save_ac_results_to_csv(all_results, ac_config, power_matrix_file, stats_file, timeseries_file)
            print(f"  âœ… {ac_id} æ•°æ®å·²ä¿å­˜ï¼Œå…±å¤„ç†{len(all_results)}å¤©")
        else:
            print(f"  âŒ {ac_id} æ— æœ‰æ•ˆæ•°æ®")
            
    except Exception as e:
        print(f"  âŒ {ac_id} å¤„ç†å¤±è´¥: {str(e)}")

def save_ac_results_to_csv(results, ac_config, power_matrix_file, stats_file, timeseries_file):
    """ä¿å­˜å•ä¸ªç©ºè°ƒçš„ç»“æœåˆ°CSVæ–‡ä»¶"""
    import pandas as pd
    
    ac_id = ac_config['id']
    ac_type = ac_config['type']
    
    # 1. ä¿å­˜åŠŸç‡çŸ©é˜µ
    with open(power_matrix_file, 'w', encoding='utf-8') as f:
        f.write(f"{ac_id} å¤šå¤©åŠŸç‡çŸ©é˜µ\n")
        f.write(f"\"ç©ºè°ƒå‚æ•°: P_rated={ac_config['P_rated']}kW, T_range=[{ac_config['T_min']}, {ac_config['T_max']}]Â°C\"\n\n")
        
        # å†™å…¥è¡¨å¤´
        header = "æ—¥æœŸ,çŠ¶æ€," + ",".join([f"t{i+1}({(i+1)*0.5}h)" for i in range(48)])
        f.write(header + "\n")
        
        # å†™å…¥æ•°æ®
        for result in results:
            if result['status'] == 'success':
                powers_str = ",".join([f"{p:.3f}" for p in result['powers']])
                f.write(f"{result['date']},{result['status']},{powers_str}\n")
    
    # 2. ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats_data = []
    for result in results:
        if result['status'] == 'success':
            stats_data.append({
                'ç©ºè°ƒID': ac_id,
                'ç©ºè°ƒç±»å‹': ac_type,
                'æ—¥æœŸ': result['date'],
                'çŠ¶æ€': result['status'],
                'æ€»èƒ½è€—(kWh)': result['total_energy'],
                'å¹³å‡åŠŸç‡(kW)': result['avg_power'],
                'æœ€å¤§åŠŸç‡(kW)': result['max_power'],
                'é¢å®šåŠŸç‡(kW)': ac_config['P_rated'],
                'æ¸©åº¦èŒƒå›´(Â°C)': f"[{ac_config['T_min']}, {ac_config['T_max']}]"
            })
    
    stats_df = pd.DataFrame(stats_data)
    stats_df.to_csv(stats_file, index=False, encoding='utf-8')
    
    # 3. ä¿å­˜å®Œæ•´æ—¶é—´åºåˆ—
    with open(timeseries_file, 'w', encoding='utf-8') as f:
        f.write(f"{ac_id} å¤šå¤©å®Œæ•´æ—¶é—´åºåˆ—æ•°æ®\n\n")
        
        for result in results:
            if result['status'] == 'success':
                f.write(f"\"æ—¥æœŸ: {result['date']}, ç©ºè°ƒ: {ac_id} ({ac_type}), çŠ¶æ€: {result['status']}\"\n")
                f.write("æ—¶é—´(h),å®¤å†…æ¸©åº¦(Â°C),ç©ºè°ƒåŠŸç‡(kW),åŠŸç‡å æ¯”(%)\n")
                
                for i in range(48):
                    time_h = (i + 1) * 0.5
                    temp = result['temperatures'][i] if i < len(result['temperatures']) else 0
                    power = result['powers'][i] if i < len(result['powers']) else 0
                    power_ratio = (power / ac_config['P_rated'] * 100) if power > 0 else 0
                    f.write(f"{time_h},{temp:.2f},{power:.3f},{power_ratio:.1f}\n")
                
                f.write("\n")

def process_remaining_days_for_all_acs(target_year=None, start_day=0, batch_size=10, selected_ac_ids=None, selected_ac_type=None):
    """
    ä¸ºæ‰€æœ‰ç©ºè°ƒåˆ†åˆ«å¤„ç†å‰©ä½™çš„å¤å­£å¤©æ•°
    
    å‚æ•°:
    target_year: è¦å¤„ç†çš„ç›®æ ‡å¹´ä»½ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰å¹´ä»½
    start_day: å¼€å§‹å¤„ç†çš„å¤©æ•°ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€å¤©ï¼‰
    batch_size: æ¯æ‰¹å¤„ç†çš„å¤©æ•°
    selected_ac_ids: æŒ‡å®šè¦å¤„ç†çš„ç©ºè°ƒIDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºå¤„ç†æ‰€æœ‰ç©ºè°ƒ
    selected_ac_type: æŒ‰ç±»å‹ç­›é€‰ç©ºè°ƒ
    """
    # ç¯å¢ƒæ£€æŸ¥
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥æœªé€šè¿‡ï¼Œç»ˆæ­¢æ‰§è¡Œ")
        return
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_file_path = check_data_file()
    if not data_file_path:
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç»ˆæ­¢æ‰§è¡Œ")
        return
    
    # åŠ è½½ç©ºè°ƒé…ç½®
    ac_configs = load_ac_configs()
    if not ac_configs:
        print("âŒ æ— æ³•åŠ è½½ç©ºè°ƒé…ç½®ï¼Œç»ˆæ­¢æ‰§è¡Œ")
        return
    
    # ç­›é€‰è¦å¤„ç†çš„ç©ºè°ƒ
    if selected_ac_ids:
        ac_configs = [ac for ac in ac_configs if ac['id'] in selected_ac_ids]
        print(f"âœ… é€‰æ‹©å¤„ç†{len(ac_configs)}ä¸ªæŒ‡å®šç©ºè°ƒ: {selected_ac_ids}")
    elif selected_ac_type:
        ac_configs = [ac for ac in ac_configs if ac['type'] == selected_ac_type]
        print(f"âœ… é€‰æ‹©å¤„ç†{len(ac_configs)}ä¸ª{selected_ac_type}å‹ç©ºè°ƒ")
    else:
        print(f"âœ… å°†å¤„ç†æ‰€æœ‰{len(ac_configs)}ä¸ªç©ºè°ƒ")
    
    if not ac_configs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„ç©ºè°ƒé…ç½®")
        return
    
    # è·å–å¯ç”¨å¹´ä»½
    available_years = get_available_years(data_file_path)
    if not available_years:
        print("âŒ æ— æ³•è·å–å¯ç”¨å¹´ä»½ï¼Œç»ˆæ­¢æ‰§è¡Œ")
        return
    
    # éªŒè¯ç›®æ ‡å¹´ä»½
    if target_year is not None:
        if target_year not in available_years:
            print(f"âŒ æŒ‡å®šçš„å¹´ä»½ {target_year} ä¸åœ¨å¯ç”¨å¹´ä»½åˆ—è¡¨ä¸­")
            print(f"å¯ç”¨å¹´ä»½: {available_years}")
            return
        years_to_process = [target_year]
        print(f"âœ… å°†å¤„ç† {target_year} å¹´çš„å¤å­£æ•°æ®")
    else:
        years_to_process = available_years
        print(f"âœ… å°†å¤„ç†æ‰€æœ‰å¹´ä»½çš„å¤å­£æ•°æ®: {years_to_process}")
    
    # ä¸ºæ¯ä¸ªå¹´ä»½å’Œæ¯ä¸ªç©ºè°ƒç”Ÿæˆæ•°æ®
    total_acs = len(ac_configs)
    total_years = len(years_to_process)
    
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†: {total_acs}ä¸ªç©ºè°ƒ Ã— {total_years}ä¸ªå¹´ä»½ = {total_acs * total_years}ä¸ªä»»åŠ¡")
    print("=" * 100)
    
    for year_idx, year in enumerate(years_to_process):
        print(f"\nğŸ—“ï¸  å¤„ç†å¹´ä»½: {year} [{year_idx+1}/{total_years}]")
        print("ğŸ”„" * 50)
        
        for ac_idx, ac_config in enumerate(ac_configs):
            print(f"\n[{ac_idx+1}/{total_acs}] ç©ºè°ƒ: {ac_config['id']} - å¹´ä»½: {year}")
            
            try:
                # ä¸ºæ¯ä¸ªç©ºè°ƒç”Ÿæˆå¤šå¤©æ•°æ®
                generate_single_ac_multi_day_data(
                    ac_config=ac_config, 
                    target_year=year, 
                    start_day=start_day, 
                    batch_size=batch_size, 
                    data_file_path=data_file_path
                )
                
                # æ¯ä¸ªç©ºè°ƒå¤„ç†å®ŒåçŸ­æš‚æš‚åœ
                time.sleep(1)
                
            except Exception as e:
                print(f"  âŒ å¤„ç†ç©ºè°ƒ {ac_config['id']} æ—¶å‡ºé”™: {str(e)}")
                continue
    
    print(f"\nğŸ‰ æ‰€æœ‰ç©ºè°ƒçš„å¤šå¹´å¤å­£æ•°æ®å¤„ç†å®Œæˆ!")
    print(f"ç”Ÿæˆçš„æ–‡ä»¶æ ¼å¼: [ç©ºè°ƒID]_multi_day_[ç±»å‹].csv")

if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ä¸ºæ¯ä¸ªç©ºè°ƒç”Ÿæˆå¤šå¹´å¤å­£ä¼˜åŒ–æ•°æ®')
    parser.add_argument('--year', type=str, help='è¦å¤„ç†çš„å¹´ä»½ï¼Œå¦‚2015ã€2016ç­‰ï¼Œä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰å¹´ä»½')
    parser.add_argument('--start', type=int, default=0, help='å¼€å§‹å¤„ç†çš„å¤©æ•°ç´¢å¼•ï¼ˆ0è¡¨ç¤ºç¬¬ä¸€å¤©ï¼‰ï¼Œé»˜è®¤ä¸º0')
    parser.add_argument('--batch', type=int, default=10, help='æ¯æ‰¹å¤„ç†çš„å¤©æ•°ï¼Œé»˜è®¤ä¸º10')
    parser.add_argument('--ac-ids', type=str, nargs='*', help='æŒ‡å®šè¦å¤„ç†çš„ç©ºè°ƒIDï¼Œå¦‚ AC_S_001 AC_M_001ï¼Œä¸æŒ‡å®šåˆ™å¤„ç†æ‰€æœ‰ç©ºè°ƒ')
    parser.add_argument('--ac-type', type=str, choices=['small', 'medium', 'large'], help='æŒ‰ç©ºè°ƒç±»å‹ç­›é€‰ï¼Œå¯é€‰small/medium/large')
    parser.add_argument('--list-acs', action='store_true', help='ä»…åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ç©ºè°ƒIDå’Œç±»å‹ï¼Œä¸è¿›è¡Œå¤„ç†')
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯è¦åˆ—å‡ºç©ºè°ƒ
    if args.list_acs:
        ac_configs = load_ac_configs()
        if ac_configs:
            print(f"\nğŸ“‹ å¯ç”¨ç©ºè°ƒåˆ—è¡¨ (å…±{len(ac_configs)}ä¸ª):")
            print("-" * 60)
            
            # æŒ‰ç±»å‹åˆ†ç»„
            by_type = {'small': [], 'medium': [], 'large': []}
            for ac in ac_configs:
                by_type[ac['type']].append(ac)
            
            for ac_type_key, acs_list in by_type.items():
                if acs_list:
                    print(f"\n{ac_type_key.upper()}å‹ç©ºè°ƒ ({len(acs_list)}ä¸ª):")
                    for ac_item in acs_list:
                        print(f"  {ac_item['id']}: P_rated={ac_item['P_rated']}kW, T_range=[{ac_item['T_min']}, {ac_item['T_max']}]Â°C")
        exit(0)
    
    # æ‰§è¡Œæ•°æ®å¤„ç†
    fixed_processing_years = ["2015", "2017", "2018", "2019", "2020", "2021"]

    if args.year:
        print(f"â„¹ï¸  æ³¨æ„: æ£€æµ‹åˆ°å‘½ä»¤è¡Œå‚æ•° --year '{args.year}'ã€‚")
        print(f"è„šæœ¬å°†æŒ‰ç…§é¢„è®¾çš„å¹´ä»½åˆ—è¡¨å¤„ç†æ•°æ®: {fixed_processing_years}ã€‚")
        if args.year not in fixed_processing_years:
             print(f"å‘½ä»¤è¡ŒæŒ‡å®šçš„å¹´ä»½ '{args.year}' ä¸åœ¨é¢„è®¾åˆ—è¡¨ä¸­ï¼Œä½†ä»ä¼šæŒ‰é¢„è®¾åˆ—è¡¨æ‰§è¡Œã€‚")
        print("å¦‚æœæ‚¨åªæƒ³å¤„ç†å‘½ä»¤è¡ŒæŒ‡å®šçš„å•ä¸ªå¹´ä»½ï¼Œè¯·è€ƒè™‘ä¿®æ”¹è„šæœ¬æˆ–ç§»é™¤é¢„è®¾å¹´ä»½åˆ—è¡¨çš„é€»è¾‘ã€‚")
    
    print(f"\nğŸš€ å³å°†æŒ‰é¢„è®¾å¹´ä»½åˆ—è¡¨ä¸ºæ‰€æœ‰(æˆ–é€‰å®š)ç©ºè°ƒå¤„ç†æ•°æ®: {fixed_processing_years}")
    print("=" * 100)

    for year_to_process in fixed_processing_years:
        print(f"\nğŸ”¥ğŸ”¥ğŸ”¥ å¼€å§‹å¤„ç†å¹´ä»½: {year_to_process} ğŸ”¥ğŸ”¥ğŸ”¥")
        process_remaining_days_for_all_acs(
            target_year=year_to_process,      # ä½¿ç”¨å¾ªç¯ä¸­çš„å½“å‰å¹´ä»½
            start_day=args.start,             # éµå¾ªå‘½ä»¤è¡Œå‚æ•°
            batch_size=args.batch,            # éµå¾ªå‘½ä»¤è¡Œå‚æ•°
            selected_ac_ids=args.ac_ids,      # éµå¾ªå‘½ä»¤è¡Œå‚æ•° (ç”¨äºç­›é€‰ç©ºè°ƒ)
            selected_ac_type=args.ac_type     # éµå¾ªå‘½ä»¤è¡Œå‚æ•° (ç”¨äºç­›é€‰ç©ºè°ƒç±»å‹)
        )
        print(f"ğŸğŸğŸ å®Œæˆå¤„ç†å¹´ä»½: {year_to_process} ğŸğŸğŸ")
        print("-" * 100)
        # æ·»åŠ ä¸€ä¸ªå°çš„å»¶æ—¶ï¼Œä½¿å¾—è¾“å‡ºæ›´æ˜“è¯»ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å¤šä¸ªå¹´ä»½æ—¶
        time.sleep(3)
    
    print("\nğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰é¢„è®¾å¹´ä»½çš„æ•°æ®å¤„ç†å®Œæˆ! ğŸ‰ğŸ‰ğŸ‰") 